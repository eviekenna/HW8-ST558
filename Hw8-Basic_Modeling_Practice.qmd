---
title: "HW8-Basic Modeling Practice"
format: html
editor: visual
---
##Reading the Data
```{r}
  library(readr)
bike_data <- read_csv("SeoulBikeData.csv", locale = locale(encoding = "latin1"))
```
##EDA
First we need to investigate the data and understand how it is stored. 

Checking for missing values in the dataset.
```{r}
colSums(is.na(bike_data))
```
We can see from the output that there are no missing values in this data set. 

Next we look at the column types and the values within the columns to make sure that they are consistent with what we would expect. Using str to show us how it is stored.

```{r}
str(bike_data)
```
Check the unique levels of Seasons and Holiday
```{r}
unique(bike_data$Seasons)
unique(bike_data$Holiday)
```
Change the way Seasons, Holiday and Functioning day are stored to be a factors with ordered levels and convert the date column to dmy using the lubridate package date column. 
```{r}
library(lubridate)
library(dplyr)
library(tidyverse)
bike_data|>
  mutate(Holiday=as.factor(Holiday),
         Seasons=factor(Seasons, levels=c("Winter","Spring","Summer","Autumn")),
         Date=dmy(Date),
         `Functioning Day`= as.factor(`Functioning Day`))


```
Look at some quick numerical summaries of the data using the psych describe package.
```{r}
psych::describe(bike_data)
```
Rename all of the variables to have easier names. 
```{r}
bike_data<- bike_data|>
  rename(Temperature=`Temperature(°C)`, Visibility=`Visibility (10m)`,DewPointTemperature=`Dew point temperature(°C)`,SolarRadiation=`Solar Radiation (MJ/m2)`,Humidity=`Humidity(%)`,WindSpeed=`Wind speed (m/s)`,Rainfall=`Rainfall(mm)`, RentedBikeCount=`Rented Bike Count`, Snowfall=`Snowfall (cm)`,FunctioningDay=`Functioning Day`)
```
Looking at some summary statistics of the numerical data.
```{r}
library(dplyr)
bike_data |>
  summarize(across(where(is.numeric),
                   list(mean = mean, median = median, sd = sd, min = min, max = max),
                   .names = "{.fn}_{.col}"))
```

Now focusing on RentedBikeCount accross the catagorical variables.
```{r}
library(dplyr)
bike_data |>
  group_by(Seasons) |>
  summarize(mean_rent = mean(RentedBikeCount),
            median_rent = median(RentedBikeCount),
            sd_rent = sd(RentedBikeCount),
            n = n())

bike_data |>
  group_by(Holiday) |>
  summarize(mean_rent = mean(RentedBikeCount),
            median_rent = median(RentedBikeCount),
            sd_rent = sd(RentedBikeCount))

bike_data |>
  group_by(FunctioningDay) |>
  summarize(mean_rent = mean(RentedBikeCount),
            median_rent = median(RentedBikeCount))

```
After looking at the summaries accross the data here the FunctioningDay data is always yes and never no so it provides no useful information for analysis so the decision here is to drop that column. 
```{r}
bike_data <- bike_data |> select(-FunctioningDay)
```
Summarizing across the hours so that each day has one observation associated with it. 
```{r}
library(dplyr)

bike_daily <- bike_data |>
  group_by(Date, Seasons, Holiday) |>
  summarize(
    # totals per day
    TotalBikes = sum(RentedBikeCount, na.rm = TRUE),
    TotalRainfall = sum(Rainfall, na.rm = TRUE),
    TotalSnowfall = sum(Snowfall, na.rm = TRUE),

    # daily mean weather conditions
    MeanTemp = mean(Temperature, na.rm = TRUE),
    MeanHumidity = mean(Humidity, na.rm = TRUE),
    MeanWindSpeed = mean(WindSpeed, na.rm = TRUE),
    MeanVisibility = mean(Visibility, na.rm = TRUE),
    MeanDewPoint = mean(DewPointTemperature, na.rm = TRUE),
    MeanSolarRadiation = mean(SolarRadiation, na.rm = TRUE),
    .groups = "drop"
  )

```
Creating a summary of the variables in the new data frame. 
```{r}
library(dplyr)

# Overall summaries for variables
daily_summary <- bike_daily |>
  summarize(
    n_days        = n(),
    bikes_mean    = mean(TotalBikes),  bikes_sd = sd(TotalBikes),
    bikes_median  = median(TotalBikes), bikes_IQR = IQR(TotalBikes),
    rain_sum      = sum(TotalRainfall), snow_sum = sum(TotalSnowfall),
    temp_mean     = mean(MeanTemp),     temp_sd  = sd(MeanTemp),
    hum_mean      = mean(MeanHumidity), wind_mean = mean(MeanWindSpeed),
    vis_mean      = mean(MeanVisibility), dew_mean = mean(MeanDewPoint),
    solar_mean    = mean(MeanSolarRadiation)
  )
daily_summary

```
Looking at summaries based on Season and Holiday. 
```{r}
# Summaries by Season and Holiday
by_season <- bike_daily |>
  group_by(Seasons) |>
  summarise(
    days = n(),
    bikes_mean = mean(TotalBikes), bikes_median = median(TotalBikes),
    temp_mean  = mean(MeanTemp),   rain_sum = sum(TotalRainfall),
    .groups = "drop"
  )

by_holiday <- bike_daily |>
  group_by(Holiday) |>
  summarise(
    days = n(),
    bikes_mean = mean(TotalBikes), bikes_median = median(TotalBikes),
    rain_sum   = sum(TotalRainfall), snow_sum = sum(TotalSnowfall),
    .groups = "drop"
  )

by_season
by_holiday
```
A few plots to visualize the data better. 
```{r}
library(ggplot2)
#Temperature vs Rentals
ggplot(bike_daily, aes(x = MeanTemp, y = TotalBikes, color = Seasons)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = FALSE) +
  labs(title = "Temperature vs Total Bikes Rented", x = "Mean Daily Temp (°C)", y = "Total Bikes Rented")

```


```{r}
# Boxplots of rentals by Season and Holiday
#Season
ggplot(bike_daily, aes(x = Seasons, y = TotalBikes, fill = Seasons)) +
  geom_boxplot(outlier.alpha = 0.3) +
  labs(title = "Distribution of Daily Rentals by Season", x = "Season", y = "Total Bikes Rented") +
  theme(legend.position = "none")
#Holiday
ggplot(bike_daily, aes(x = Holiday, y = TotalBikes, fill = Holiday)) +
  geom_boxplot(outlier.alpha = 0.3) +
  labs(title = "Daily Rentals: Holiday vs Non-Holiday", x = "Holiday", y = "Total Bikes") +
  theme(legend.position = "none")

```
Seeing if there are any correlations between the numeric variables
```{r}

library(ggplot2)
library(dplyr)
library(tidyr)

bike_daily |>
  select(where(is.numeric)) |>
  pivot_longer(everything(), names_to = "Variable", values_to = "Value") |>
  ggplot(aes(x = Value, fill = Variable)) +
  geom_histogram(show.legend = FALSE, bins = 30, alpha = 0.7) +
  facet_wrap(~ Variable, scales = "free", ncol = 3) +
  labs(title = "Distribution of Numeric Variables",
       x = "Value", y = "Frequency") +
  theme_minimal()
```
```{r}
num_vars <- c("MeanTemp", "MeanHumidity", "MeanWindSpeed",
              "TotalRainfall", "TotalSnowfall", "MeanVisibility")

for (v in num_vars) {
  p <- ggplot(bike_daily, aes_string(x = v, y = "TotalBikes")) +
    geom_point(alpha = 0.5, color = "darkblue") +
    geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 0.8) +
    labs(title = paste("Total Bikes vs", v),
         x = v, y = "Total Daily Rentals") +
    theme_minimal()
  print(p)
}
```
## Slitting the Data
Splitting the data using tidymodels split and stratifying based on seasons. Using a 25/75 split. 
```{r}
library(tidymodels)
set.seed(123)  # for reproducibility
bike_daily<- bike_daily|>
  mutate(Date= as.Date(Date, format="%d/%m/%Y"))

# 75/25 split, stratified by Seasons
bike_split <- initial_split(bike_daily, prop = 0.75, strata = Seasons)

# Create training and testing sets
bike_train <- training(bike_split)
bike_test  <- testing(bike_split)

# check sizes
nrow(bike_train)
nrow(bike_test)
```
```{r}
bike_train <- bike_train |>
  mutate(Date = as.Date(Date, format = "%d/%m/%Y"))

bike_test <- bike_test |>
  mutate(Date = as.Date(Date, format = "%d/%m/%Y"))

```

Creating a 10-fold CV split on the training set
```{r}
library(tidymodels)

# 10-fold cross-validation, stratified by Seasons
set.seed(123)
bike_folds <- vfold_cv(bike_train, v = 10, strata = Seasons)

# View structure
bike_folds

```
#Fitting MLR Models


```{r}
library(tidymodels)
library(dplyr)
#1st Recipie
rec_mlr_1 <- recipe(TotalBikes ~ ., data = bike_train) |>
  # 1) Derive day-of-week from Date, then build weekday/weekend factor
  step_date(Date, features = "dow", label = TRUE) |>        # creates Date_dow as ordered factor (Mon,...,Sun)
  step_mutate(day_type = factor(if_else(Date_dow %in% c("Sat","Sun"),
                                        "Weekend", "Weekday"))) |>
  step_rm(Date_dow) |>                                       # drop intermediate
  update_role(Date, new_role = "ID") |>                      # keep Date only as an ID (ignored by model)

  # 2) Standardize numeric predictors (scales differ)
  step_normalize(all_numeric_predictors()) |>

  # 3) Dummy-code categorical predictors (Seasons, Holiday, day_type)
  step_dummy(all_nominal_predictors(), one_hot = TRUE)



```
```{r}
library(tidymodels)
library(dplyr)

# Recipe 2
rec_mlr_2 <- recipe(TotalBikes ~ ., data = bike_train) |>
  # 1) Use Date to create weekday/weekend, then keep Date as an ID
  step_date(Date, features = "dow", label = TRUE) |>               # creates Date_dow
  step_mutate(day_type = factor(if_else(Date_dow %in% c("Sat","Sun"),
                                        "Weekend", "Weekday"))) |>
  step_rm(Date_dow) |>
  update_role(Date, new_role = "ID") |>                             # exclude from modeling

  # 2) Dummy-code categorical predictors (Seasons, Holiday, day_type)
  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>

  # 3) Add interactions:
  #    - Seasons × Holiday  (all season dummies with all holiday dummies)
  #    - Seasons × MeanTemp (each season dummy with temperature)
  #    - MeanTemp × TotalRainfall
  step_interact(terms = ~ starts_with("Seasons_"):starts_with("Holiday_")
                        + starts_with("Seasons_"):MeanTemp
                        + MeanTemp:TotalRainfall) |>

  # 4) Standardize all numeric predictors (after creating interaction columns)
  step_normalize(all_numeric_predictors())



```

```{r}
library(tidymodels)
library(dplyr)

# Identify the ORIGINAL numeric predictors 
num_base <- bike_train |>
  select(where(is.numeric), -TotalBikes) |>
  names()

# Recipe 3
rec_mlr_3 <- recipe(TotalBikes ~ ., data = bike_train) |>
  # 1) Derive weekday/weekend from Date; keep Date only as an ID
  step_date(Date, features = "dow", label = TRUE) |>
  step_mutate(day_type = factor(if_else(Date_dow %in% c("Sat","Sun"),
                                        "Weekend", "Weekday"))) |>
  step_rm(Date_dow) %>%
  update_role(Date, new_role = "ID") |>

  # 2) Dummy-code categorical predictors first (so we can form interactions with dummies)
  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>

  # 3) Interactions (same as Recipe 2)
  step_interact(terms = ~ starts_with("Seasons_"):starts_with("Holiday_")
                        + starts_with("Seasons_"):MeanTemp
                        + MeanTemp:TotalRainfall) |>

  # 4) Quadratic terms 
  step_poly(all_of(num_base), degree = 2, options = list(raw = TRUE)) |>

  # 5) Standardize all numeric predictors (includes the squared terms)
  step_normalize(all_numeric_predictors())


```

```{r}
library(tidymodels)
library(dplyr)

# Model spec
lm_spec <- linear_reg() |>
  set_engine("lm")

#Workflows for the three recipes 
wf1 <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec_mlr_1)
wf2 <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec_mlr_2)
wf3 <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec_mlr_3)

wfs <- list(
  rec1 = wf1,
  rec2 = wf2,
  rec3 = wf3
)

# 10-fold CV on training set for each recipe 
set.seed(123)
ctrl <- control_resamples(save_pred = TRUE)

cv_results <- purrr::imap_dfr(
  wfs,
  ~ fit_resamples(.x, resamples = bike_folds, control = ctrl) |>
    collect_metrics() |>
    mutate(model = .y)
)

# View CV metrics (RMSE lower is better; also R^2 shown)
cv_results |> arrange(.metric, mean)

```

```{r}
# Select best by RMSE 
best_name <- cv_results |>
  filter(.metric == "rmse") |>
  arrange(mean) |>
  slice(1) |>
  pull(model)

best_wf <- wfs[[best_name]]
best_name

```
```{r}
# Fit best model on entire training and evaluate on test
set.seed(123)
final_res <- last_fit(best_wf, split = bike_split)

# Test-set metrics (includes RMSE)
final_metrics <- collect_metrics(final_res)
final_metrics

```

```{r}
# Coefficient table from the final model
final_coefs <- final_res |>
  extract_workflow() |>
  extract_fit_parsnip() |>
  tidy()

final_coefs

```

